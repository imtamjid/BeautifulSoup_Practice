import requests
from bs4 import BeautifulSoup
import csv
# Make a request
page = requests.get(
    "https://realpython.github.io/fake-jobs/")
soup = BeautifulSoup(page.content, 'html.parser')

# Create top_items as empty list
all_jobs = []

# Extract and store in top_items according to instructions on the left
jobs = soup.find_all("div", {"class": "card"})
for job in jobs:
    job_title = job.find('h2').text.strip()
    company = job.find('h3').text.strip()
    location = job.find('p').text.strip()
    date = job.find('time').text.strip()
    

    all_jobs.append({
        "job_title": job_title,
        "company":   company,
		    "location": location,
        "date": date,     
    })

for i in all_jobs:
    print (i)

keys = all_jobs[0].keys()

with open('jobs.csv', 'w', newline='') as output_file:
    dict_writer = csv.DictWriter(output_file, keys)
    dict_writer.writeheader()
    dict_writer.writerows(all_jobs)
